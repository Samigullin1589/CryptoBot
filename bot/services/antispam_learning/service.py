# bot/services/antispam_learning/service.py
"""
–ì–ª–∞–≤–Ω—ã–π —Å–µ—Ä–≤–∏—Å —Å–∞–º–æ–æ–±—É—á–∞–µ–º–æ–π —Å–∏—Å—Ç–µ–º—ã –∞–Ω—Ç–∏—Å–ø–∞–º–∞.
"""
from typing import Iterable, Optional, Tuple

from loguru import logger
from redis.asyncio import Redis

from bot.config.settings import settings
from bot.services.antispam_learning.cache import SpamPhraseCache
from bot.services.antispam_learning.extractor import TextPhraseExtractor
from bot.services.antispam_learning.knowledge_base import SpamKnowledgeBase
from bot.services.antispam_learning.models import ScoredPhrase, SpamStatistics
from bot.services.antispam_learning.scorer import SpamTextScorer
from bot.utils.text_utils import normalize_text


class AntiSpamLearningService:
    """
    –°–∞–º–æ–æ–±—É—á–∞–µ–º–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–Ω—Ç–∏—Å–ø–∞–º–∞.
    
    –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
    - –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö —Å–ø–∞–º–∞ —Å –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é
    - –•—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ —Å–ø–∞–º-—Ñ—Ä–∞–∑ –∏ –¥–æ–º–µ–Ω–æ–≤
    - –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    - –ù–µ—á–µ—Ç–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏
    - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –º–µ—Ç—Ä–∏–∫–∏
    
    –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  AntiSpamLearningService (–§–∞—Å–∞–¥)  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì           ‚Üì           ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Cache        ‚îÇ ‚îÇ Knowledge ‚îÇ ‚îÇ Scorer        ‚îÇ
    ‚îÇ (Local)      ‚îÇ ‚îÇ Base      ‚îÇ ‚îÇ (Fuzzy Match) ‚îÇ
    ‚îÇ              ‚îÇ ‚îÇ (Redis)   ‚îÇ ‚îÇ               ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Phrase Extractor   ‚îÇ
    ‚îÇ (N-grams)          ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    """
    
    def __init__(self, redis: Redis):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–µ—Ä–≤–∏—Å –∞–Ω—Ç–∏—Å–ø–∞–º–∞.
        
        Args:
            redis: –ö–ª–∏–µ–Ω—Ç Redis –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        """
        self.redis = redis
        self.config = settings.security
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self._init_cache()
        self._init_knowledge_base()
        self._init_scorer()
        self._init_extractor()
        
        logger.success("‚úÖ –°–µ—Ä–≤–∏—Å AntiSpamLearningService –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def _init_cache(self) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫—ç—à —Ñ—Ä–∞–∑."""
        cache_ttl = getattr(self.config, 'learning_cache_ttl_seconds', 300)
        self.cache = SpamPhraseCache(ttl_seconds=cache_ttl)
    
    def _init_knowledge_base(self) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π."""
        self.knowledge_base = SpamKnowledgeBase(self.redis)
    
    def _init_scorer(self) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–∫–æ—Ä–µ—Ä —Ç–µ–∫—Å—Ç–∞."""
        min_ratio = getattr(self.config, 'learning_min_ratio', 80)
        scorer_type = getattr(self.config, 'learning_scorer_type', 'partial_ratio')
        
        self.scorer = SpamTextScorer(
            min_ratio=min_ratio,
            scorer_type=scorer_type
        )
    
    def _init_extractor(self) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä —Ñ—Ä–∞–∑."""
        use_trigrams = getattr(self.config, 'learning_use_trigrams', False)
        
        self.extractor = TextPhraseExtractor(use_trigrams=use_trigrams)
    
    async def add_feedback(
        self,
        text: str,
        domains: Optional[Iterable[str]] = None
    ) -> None:
        """
        –û–±—É—á–∞–µ—Ç —Å–∏—Å—Ç–µ–º—É –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ —Å–ø–∞–º–∞.
        
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º –ø–æ—Å–ª–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Å–ø–∞–º–∞.
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Ö –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π.
        
        Args:
            text: –¢–µ–∫—Å—Ç —Å–ø–∞–º–∞
            domains: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –¥–æ–º–µ–Ω—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞
        """
        if not text:
            logger.warning("‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –ø—É—Å—Ç–æ–º —Ç–µ–∫—Å—Ç–µ")
            return
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç
        normalized = normalize_text(text)
        
        if not normalized:
            logger.warning("‚ö†Ô∏è –¢–µ–∫—Å—Ç —Å—Ç–∞–ª –ø—É—Å—Ç—ã–º –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏")
            return
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ—Ä–∞–∑—ã
        phrases = self.extractor.extract_phrases(normalized)
        
        if not phrases:
            logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ñ—Ä–∞–∑—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞")
            return
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ—Ä–∞–∑—ã –≤ –±–∞–∑—É
        phrases_added = await self.knowledge_base.add_phrases(phrases)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–º–µ–Ω—ã –µ—Å–ª–∏ –µ—Å—Ç—å
        domains_added = 0
        if domains:
            domains_added = await self.knowledge_base.add_domains(domains)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∏–º–µ—Ä
        await self.knowledge_base.add_sample(text)
        
        # –ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∫—ç—à –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        self.cache.invalidate()
        
        logger.success(
            f"‚úÖ –ë–∞–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞: {phrases_added} —Ñ—Ä–∞–∑, "
            f"{domains_added} –¥–æ–º–µ–Ω–æ–≤ –¥–æ–±–∞–≤–ª–µ–Ω–æ"
        )
    
    async def score_text(self, text: str) -> Tuple[int, Optional[ScoredPhrase]]:
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ö–æ–∂–µ—Å—Ç—å —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º —Å–ø–∞–º–æ–º.
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ü–µ–Ω–∫–∞ 0-100, —Å–æ–≤–ø–∞–≤—à–∞—è —Ñ—Ä–∞–∑–∞ –∏–ª–∏ None)
        """
        if not text:
            return 0, None
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç
        normalized = normalize_text(text)
        
        if not normalized:
            return 0, None
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ—Ä–∞–∑ (—Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º)
        phrases = await self._get_cached_phrases()
        
        if not phrases:
            logger.debug("‚ÑπÔ∏è –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø—É—Å—Ç–∞, –æ—Ü–µ–Ω–∫–∞ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞")
            return 0, None
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç
        return self.scorer.score(normalized, phrases)
    
    async def is_bad_domain(self, host: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ–º–µ–Ω –Ω–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–µ –≤ —á–µ—Ä–Ω–æ–º —Å–ø–∏—Å–∫–µ.
        
        Args:
            host: –î–æ–º–µ–Ω–Ω–æ–µ –∏–º—è
            
        Returns:
            True –µ—Å–ª–∏ –¥–æ–º–µ–Ω –≤ —á–µ—Ä–Ω–æ–º —Å–ø–∏—Å–∫–µ
        """
        if not host:
            return False
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ü–µ–Ω–∫—É –¥–æ–º–µ–Ω–∞
        score = await self.knowledge_base.get_domain_score(host)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –ø–æ—Ä–æ–≥—É
        min_score = getattr(self.config, 'learning_domain_min_score', 3.0)
        is_bad = score >= min_score
        
        if is_bad:
            logger.warning(
                f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–ª–æ—Ö–æ–π –¥–æ–º–µ–Ω: {host} "
                f"(–æ—Ü–µ–Ω–∫–∞: {score:.1f}, –ø–æ—Ä–æ–≥: {min_score})"
            )
        
        return is_bad
    
    async def get_domain_score(self, host: str) -> float:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –¥–æ–º–µ–Ω–∞.
        
        Args:
            host: –î–æ–º–µ–Ω–Ω–æ–µ –∏–º—è
            
        Returns:
            –û—Ü–µ–Ω–∫–∞ –¥–æ–º–µ–Ω–∞ (0.0 –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω)
        """
        return await self.knowledge_base.get_domain_score(host)
    
    async def _get_cached_phrases(self) -> list[str]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ—Ä–∞–∑ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫—ç—à–∞.
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ø–∞–º-—Ñ—Ä–∞–∑
        """
        # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –∫—ç—à–∞
        cached = self.cache.get()
        
        if cached is not None:
            return cached
        
        # –ö—ç—à –ø—É—Å—Ç –∏–ª–∏ —É—Å—Ç–∞—Ä–µ–ª - –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –±–∞–∑—ã
        top_k = getattr(self.config, 'learning_top_k', 500)
        phrases = await self.knowledge_base.get_top_phrases(top_k)
        
        if phrases:
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
            self.cache.set(phrases)
            logger.info(f"üì¶ –ö—ç—à –æ–±–Ω–æ–≤–ª–µ–Ω –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {len(phrases)} —Ñ—Ä–∞–∑")
        else:
            logger.warning("‚ö†Ô∏è –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø—É—Å—Ç–∞")
        
        return phrases
    
    async def get_statistics(self) -> SpamStatistics:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏ —Å–∏—Å—Ç–µ–º—ã.
        
        Returns:
            –û–±—ä–µ–∫—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã
            phrases_count = await self.knowledge_base.get_phrase_count()
            domains_count = await self.knowledge_base.get_domain_count()
            samples_count = await self.knowledge_base.get_sample_count()
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∫—ç—à–∞
            cache_stats = self.cache.get_stats()
            
            stats = SpamStatistics(
                phrases_count=phrases_count,
                domains_count=domains_count,
                samples_count=samples_count,
                cache_valid=cache_stats["valid"],
                cache_size=cache_stats["size"]
            )
            
            logger.debug(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats.to_dict()}")
            return stats
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}", exc_info=True)
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            return SpamStatistics(
                phrases_count=0,
                domains_count=0,
                samples_count=0,
                cache_valid=False,
                cache_size=0
            )
    
    async def invalidate_cache(self) -> None:
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∫—ç—à."""
        self.cache.invalidate()
        logger.info("üîÑ –ö—ç—à –∏–Ω–≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω –ø–æ –∑–∞–ø—Ä–æ—Å—É")
    
    def get_cache_stats(self) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–∞."""
        return self.cache.get_stats()