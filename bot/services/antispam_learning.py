# bot/services/antispam_learning.py
import time
from dataclasses import dataclass
from typing import Iterable, List, Optional, Tuple

from loguru import logger
from rapidfuzz import fuzz
from redis.asyncio import Redis

from bot.config.settings import settings
from bot.utils.keys import KeyFactory
from bot.utils.text_utils import normalize_text


@dataclass(frozen=True)
class ScoredPhrase:
    """
    –°–ø–∞–º-—Ñ—Ä–∞–∑–∞ —Å –æ—Ü–µ–Ω–∫–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏.
    
    Attributes:
        phrase: –¢–µ–∫—Å—Ç —Ñ—Ä–∞–∑—ã
        score: –û—Ü–µ–Ω–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏ (0-100)
    """
    phrase: str
    score: float


class SpamPhraseCache:
    """
    –ö—ç—à —Ç–æ–ø —Å–ø–∞–º-—Ñ—Ä–∞–∑ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
    
    –£–º–µ–Ω—å—à–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞—â–µ–Ω–∏–π –∫ Redis –ø—É—Ç–µ–º –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
    –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã—Ö —Å–ø–∞–º-—Ñ—Ä–∞–∑.
    """
    
    def __init__(self, ttl_seconds: int = 300):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫—ç—à —Ñ—Ä–∞–∑.
        
        Args:
            ttl_seconds: –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ –∫—ç—à–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        """
        self._phrases: List[str] = []
        self._expiry_time: float = 0.0
        self._ttl_seconds = ttl_seconds
    
    def get(self) -> Optional[List[str]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã –µ—Å–ª–∏ –∫—ç—à –≤–∞–ª–∏–¥–µ–Ω.
        
        Returns:
            Optional[List[str]]: –°–ø–∏—Å–æ–∫ —Ñ—Ä–∞–∑ –∏–ª–∏ None –µ—Å–ª–∏ –∫—ç—à —É—Å—Ç–∞—Ä–µ–ª
        """
        if not self.is_valid():
            return None
        return self._phrases.copy()
    
    def set(self, phrases: List[str]) -> None:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ—Ä–∞–∑—ã –≤ –∫—ç—à.
        
        Args:
            phrases: –°–ø–∏—Å–æ–∫ —Ñ—Ä–∞–∑ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        self._phrases = phrases
        self._expiry_time = time.monotonic() + self._ttl_seconds
        logger.debug(f"üì¶ –ö—ç—à –æ–±–Ω–æ–≤–ª–µ–Ω: {len(phrases)} —Ñ—Ä–∞–∑")
    
    def is_valid(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –∫—ç—à–∞.
        
        Returns:
            bool: True –µ—Å–ª–∏ –∫—ç—à –∞–∫—Ç—É–∞–ª–µ–Ω
        """
        return time.monotonic() < self._expiry_time and bool(self._phrases)
    
    def invalidate(self) -> None:
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∫—ç—à."""
        self._expiry_time = 0.0
        self._phrases = []
        logger.debug("üîÑ –ö—ç—à —Ñ—Ä–∞–∑ –∏–Ω–≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω")


class TextPhraseExtractor:
    """
    –ö–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑ –∏–∑ —Ç–µ–∫—Å—Ç–∞.
    
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ –∏ –±–∏–≥—Ä–∞–º–º—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–ø–∞–º–∞.
    """
    
    @staticmethod
    def extract_phrases(text: str, max_tokens: int = 50) -> set[str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞.
        
        Args:
            text: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
            
        Returns:
            set[str]: –ù–∞–±–æ—Ä —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ—Ä–∞–∑
        """
        if not text:
            return set()
        
        tokens = [
            token for token in text.split()
            if len(token) >= 5
        ][:max_tokens]
        
        phrases = set(tokens)
        
        for i in range(len(tokens) - 1):
            bigram = f"{tokens[i]} {tokens[i + 1]}"
            if 8 <= len(bigram) <= 64:
                phrases.add(bigram)
        
        return phrases


class SpamKnowledgeBase:
    """
    –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –æ —Å–ø–∞–º–µ –≤ Redis.
    
    –£–ø—Ä–∞–≤–ª—è–µ—Ç —Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–ø–∞–º-—Ñ—Ä–∞–∑–∞—Ö,
    –¥–æ–º–µ–Ω–∞—Ö –∏ –ø—Ä–∏–º–µ—Ä–∞—Ö —Å–ø–∞–º–∞.
    """
    
    def __init__(self, redis: Redis):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π.
        
        Args:
            redis: –ö–ª–∏–µ–Ω—Ç Redis
        """
        self.redis = redis
        self.keys = KeyFactory
        self.config = settings.security
    
    async def add_phrases(self, phrases: set[str]) -> int:
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç —Ñ—Ä–∞–∑—ã –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π.
        
        Args:
            phrases: –ù–∞–±–æ—Ä —Ñ—Ä–∞–∑ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
            
        Returns:
            int: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑
        """
        if not phrases:
            return 0
        
        try:
            pipe = self.redis.pipeline()
            
            for phrase in phrases:
                pipe.zincrby(self.keys.spam_phrases(), 1.0, phrase)
            
            max_phrases = getattr(self.config, 'learning_max_phrases', 10000)
            pipe.zremrangebyrank(
                self.keys.spam_phrases(),
                0,
                -(max_phrases + 1)
            )
            
            await pipe.execute()
            return len(phrases)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ñ—Ä–∞–∑: {e}")
            return 0
    
    async def add_domains(self, domains: Iterable[str]) -> int:
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç –¥–æ–º–µ–Ω—ã –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π.
        
        Args:
            domains: –°–ø–∏—Å–æ–∫ –¥–æ–º–µ–Ω–æ–≤
            
        Returns:
            int: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤
        """
        domains_list = list(domains)
        if not domains_list:
            return 0
        
        try:
            pipe = self.redis.pipeline()
            
            for domain in domains_list:
                pipe.zincrby(self.keys.spam_domains(), 1.0, domain.lower())
            
            max_domains = getattr(self.config, 'learning_max_domains', 5000)
            pipe.zremrangebyrank(
                self.keys.spam_domains(),
                0,
                -(max_domains + 1)
            )
            
            await pipe.execute()
            return len(domains_list)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–æ–º–µ–Ω–æ–≤: {e}")
            return 0
    
    async def add_sample(self, text: str) -> bool:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–∏–º–µ—Ä —Å–ø–∞–º–∞.
        
        Args:
            text: –¢–µ–∫—Å—Ç —Å–ø–∞–º–∞
            
        Returns:
            bool: True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ
        """
        try:
            pipe = self.redis.pipeline()
            
            pipe.lpush(self.keys.spam_samples(), text[:2000])
            
            max_samples = getattr(self.config, 'learning_max_samples', 1000)
            pipe.ltrim(self.keys.spam_samples(), 0, max_samples - 1)
            
            await pipe.execute()
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–∏–º–µ—Ä–∞: {e}")
            return False
    
    async def get_top_phrases(self, limit: int) -> List[str]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Ç–æ–ø —Å–ø–∞–º-—Ñ—Ä–∞–∑ –∏–∑ –±–∞–∑—ã.
        
        Args:
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ—Ä–∞–∑
            
        Returns:
            List[str]: –°–ø–∏—Å–æ–∫ —Ñ—Ä–∞–∑
        """
        try:
            phrases_bytes = await self.redis.zrevrange(
                self.keys.spam_phrases(),
                0,
                limit - 1
            )
            return [p.decode("utf-8", "ignore") for p in phrases_bytes]
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ—Ä–∞–∑: {e}")
            return []
    
    async def get_domain_score(self, domain: str) -> float:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –¥–æ–º–µ–Ω–∞ –∏–∑ –±–∞–∑—ã.
        
        Args:
            domain: –î–æ–º–µ–Ω–Ω–æ–µ –∏–º—è
            
        Returns:
            float: –û—Ü–µ–Ω–∫–∞ –¥–æ–º–µ–Ω–∞
        """
        try:
            score = await self.redis.zscore(
                self.keys.spam_domains(),
                domain.lower()
            )
            return score or 0.0
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ–º–µ–Ω–∞ '{domain}': {e}")
            return 0.0


class SpamTextScorer:
    """
    –ö–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å—Ö–æ–∂–µ—Å—Ç—å —Å–æ —Å–ø–∞–º–æ–º.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ—á–µ—Ç–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ö–æ–∂–µ—Å—Ç–∏
    —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ —Å–ø–∞–º-—Ñ—Ä–∞–∑–∞–º–∏.
    """
    
    def __init__(self, min_ratio: int = 80):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—Ü–µ–Ω—â–∏–∫ —Ç–µ–∫—Å—Ç–∞.
        
        Args:
            min_ratio: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ (0-100)
        """
        self.min_ratio = min_ratio
    
    def score(self, text: str, phrases: List[str]) -> Tuple[int, Optional[ScoredPhrase]]:
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ö–æ–∂–µ—Å—Ç—å —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ —Å–ø–∞–º-—Ñ—Ä–∞–∑–∞–º–∏.
        
        Args:
            text: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            phrases: –°–ø–∏—Å–æ–∫ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Å–ø–∞–º-—Ñ—Ä–∞–∑
            
        Returns:
            Tuple[int, Optional[ScoredPhrase]]: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Å–∫–æ—Ä –∏ —Ñ—Ä–∞–∑–∞
        """
        if not text or not phrases:
            return 0, None
        
        best_match = fuzz.process.extractOne(
            text,
            phrases,
            scorer=fuzz.partial_ratio,
            score_cutoff=self.min_ratio,
        )
        
        if best_match:
            phrase, score, _ = best_match
            logger.debug(f"üéØ –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: '{phrase}' ({score:.1f}%)")
            return int(score), ScoredPhrase(phrase, float(score))
        
        return 0, None


class AntiSpamLearningService:
    """
    –°–∞–º–æ–æ–±—É—á–∞–µ–º–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–Ω—Ç–∏—Å–ø–∞–º–∞.
    
    –•—Ä–∞–Ω–∏—Ç –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–ø–∞–º-—Ñ—Ä–∞–∑—ã –∏ –¥–æ–º–µ–Ω—ã, –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ
    –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –æ—Ç –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤.
    
    –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
    - –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    - –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –≤ Redis
    - –ù–µ—á–µ—Ç–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫
    - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑
    """
    
    def __init__(self, redis: Redis):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–µ—Ä–≤–∏—Å –æ–±—É—á–µ–Ω–∏—è.
        
        Args:
            redis: –ö–ª–∏–µ–Ω—Ç Redis
        """
        self.redis = redis
        self.config = settings.security
        
        cache_ttl = getattr(self.config, 'learning_cache_ttl_seconds', 300)
        self.cache = SpamPhraseCache(ttl_seconds=cache_ttl)
        
        self.knowledge_base = SpamKnowledgeBase(redis)
        
        min_ratio = getattr(self.config, 'learning_min_ratio', 80)
        self.scorer = SpamTextScorer(min_ratio=min_ratio)
        
        self.phrase_extractor = TextPhraseExtractor()
        
        logger.info("‚úÖ –°–µ—Ä–≤–∏—Å AntiSpamLearningService –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
    
    async def add_feedback(
        self,
        text: str,
        domains: Optional[Iterable[str]] = None
    ) -> None:
        """
        –û–±—É—á–∞–µ—Ç —Å–∏—Å—Ç–µ–º—É –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ —Å–ø–∞–º–∞.
        
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Å–ø–∞–º–∞ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º.
        
        Args:
            text: –¢–µ–∫—Å—Ç —Å–ø–∞–º–∞
            domains: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –¥–æ–º–µ–Ω—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞
        """
        normalized = normalize_text(text)
        
        if not normalized:
            logger.warning("‚ö†Ô∏è –ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return
        
        phrases = self.phrase_extractor.extract_phrases(normalized)
        
        phrases_added = await self.knowledge_base.add_phrases(phrases)
        domains_added = 0
        
        if domains:
            domains_added = await self.knowledge_base.add_domains(domains)
        
        await self.knowledge_base.add_sample(text)
        
        self.cache.invalidate()
        
        logger.success(
            f"‚úÖ –ë–∞–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞: {phrases_added} —Ñ—Ä–∞–∑, "
            f"{domains_added} –¥–æ–º–µ–Ω–æ–≤"
        )
    
    async def score_text(self, text: str) -> Tuple[int, Optional[ScoredPhrase]]:
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ö–æ–∂–µ—Å—Ç—å —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º —Å–ø–∞–º–æ–º.
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            
        Returns:
            Tuple[int, Optional[ScoredPhrase]]: –û—Ü–µ–Ω–∫–∞ –∏ —Å–æ–≤–ø–∞–≤—à–∞—è —Ñ—Ä–∞–∑–∞
        """
        normalized = normalize_text(text)
        
        if not normalized:
            return 0, None
        
        phrases = await self._get_cached_phrases()
        
        if not phrases:
            return 0, None
        
        return self.scorer.score(normalized, phrases)
    
    async def is_bad_domain(self, host: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ–º–µ–Ω –Ω–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–µ –≤ —á–µ—Ä–Ω–æ–º —Å–ø–∏—Å–∫–µ.
        
        Args:
            host: –î–æ–º–µ–Ω–Ω–æ–µ –∏–º—è
            
        Returns:
            bool: True –µ—Å–ª–∏ –¥–æ–º–µ–Ω –≤ —á–µ—Ä–Ω–æ–º —Å–ø–∏—Å–∫–µ
        """
        if not host:
            return False
        
        score = await self.knowledge_base.get_domain_score(host)
        
        min_score = getattr(self.config, 'learning_domain_min_score', 3.0)
        
        is_bad = score >= min_score
        
        if is_bad:
            logger.warning(f"‚ö†Ô∏è –ü–ª–æ—Ö–æ–π –¥–æ–º–µ–Ω: {host} (–æ—Ü–µ–Ω–∫–∞: {score})")
        
        return is_bad
    
    async def _get_cached_phrases(self) -> List[str]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ—Ä–∞–∑ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫—ç—à–∞.
        
        Returns:
            List[str]: –°–ø–∏—Å–æ–∫ —Å–ø–∞–º-—Ñ—Ä–∞–∑
        """
        cached = self.cache.get()
        
        if cached is not None:
            return cached
        
        top_k = getattr(self.config, 'learning_top_k', 500)
        phrases = await self.knowledge_base.get_top_phrases(top_k)
        
        if phrases:
            self.cache.set(phrases)
        
        return phrases
    
    async def get_statistics(self) -> dict:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π.
        
        Returns:
            dict: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        """
        try:
            pipe = self.redis.pipeline()
            pipe.zcard(self.keys.spam_phrases())
            pipe.zcard(self.keys.spam_domains())
            pipe.llen(self.keys.spam_samples())
            
            results = await pipe.execute()
            
            return {
                "phrases_count": results[0],
                "domains_count": results[1],
                "samples_count": results[2],
                "cache_valid": self.cache.is_valid(),
            }
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {}